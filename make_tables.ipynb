{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0915c118-671c-4d86-96b0-6b454a36eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5860969d-d539-4a4f-b34e-ec75ecdd4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir_tbl = 'make_tables/'\n",
    "dir_tbl = 'data_tables/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2870bf1e-29e4-4987-8050-5b4b35f32792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Family_ID</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Family_Type</th>\n",
       "      <th>Affected</th>\n",
       "      <th>Diagnosis_LAB</th>\n",
       "      <th>Mother_ID</th>\n",
       "      <th>Father_ID</th>\n",
       "      <th>Rel_Proband</th>\n",
       "      <th>...</th>\n",
       "      <th>Date sent for DNA extraction</th>\n",
       "      <th>Location of DNA extraction</th>\n",
       "      <th>DNA Box</th>\n",
       "      <th>Concentration (ng/uL)</th>\n",
       "      <th>260/280</th>\n",
       "      <th>Date sent for Sequencing</th>\n",
       "      <th>WGS Provider</th>\n",
       "      <th>(Sample Well) Plate Name.Sample.ID</th>\n",
       "      <th>Affected_orig</th>\n",
       "      <th>Affected_ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REACH000001</td>\n",
       "      <td>F0001-01</td>\n",
       "      <td>F0001</td>\n",
       "      <td>3/26/2007</td>\n",
       "      <td>trio</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Autism</td>\n",
       "      <td>F0001-02</td>\n",
       "      <td>F0001-03</td>\n",
       "      <td>Proband</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gleeson</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>9/9/2013</td>\n",
       "      <td>Illumina</td>\n",
       "      <td>LP6005688-DNA_E11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REACH000107</td>\n",
       "      <td>F0001-02</td>\n",
       "      <td>F0001</td>\n",
       "      <td>8/9/1972</td>\n",
       "      <td>trio</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Autism</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mom</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gleeson</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/9/2013</td>\n",
       "      <td>Illumina</td>\n",
       "      <td>LP6005688-DNA_F11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REACH000226</td>\n",
       "      <td>F0001-03</td>\n",
       "      <td>F0001</td>\n",
       "      <td>9/27/1969</td>\n",
       "      <td>trio</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Autism, PTSD, ADHD</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Dad</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gleeson</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/9/2013</td>\n",
       "      <td>Illumina</td>\n",
       "      <td>LP6005688-DNA_G11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REACH000002</td>\n",
       "      <td>F0002-01</td>\n",
       "      <td>F0002</td>\n",
       "      <td>11/19/2007</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Autism</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Proband</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gleeson</td>\n",
       "      <td>1</td>\n",
       "      <td>Incomplete</td>\n",
       "      <td>Incomplete</td>\n",
       "      <td>Incomplete family</td>\n",
       "      <td>Incomplete family</td>\n",
       "      <td>Incomplete family</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REACH000003</td>\n",
       "      <td>F0003-01</td>\n",
       "      <td>F0003</td>\n",
       "      <td>8/9/2000</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Autism</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Proband</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Gleeson</td>\n",
       "      <td>1</td>\n",
       "      <td>Incomplete</td>\n",
       "      <td>Incomplete</td>\n",
       "      <td>Incomplete family</td>\n",
       "      <td>Incomplete family</td>\n",
       "      <td>Incomplete family</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>REACH000889</td>\n",
       "      <td>F0320-02</td>\n",
       "      <td>F0320</td>\n",
       "      <td>1/15/1981</td>\n",
       "      <td>multiple</td>\n",
       "      <td>No</td>\n",
       "      <td>Crohn's Disease, Lupus (SLE)</td>\n",
       "      <td>F8888-88</td>\n",
       "      <td>F8888-88</td>\n",
       "      <td>Mom</td>\n",
       "      <td>...</td>\n",
       "      <td>2/28/2017</td>\n",
       "      <td>Sebat</td>\n",
       "      <td>11</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1.79</td>\n",
       "      <td>pending</td>\n",
       "      <td>pending</td>\n",
       "      <td>pending</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>REACH000890</td>\n",
       "      <td>F0320-03</td>\n",
       "      <td>F0320</td>\n",
       "      <td>7/9/1980</td>\n",
       "      <td>multiple</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F8888-88</td>\n",
       "      <td>F8888-88</td>\n",
       "      <td>Dad</td>\n",
       "      <td>...</td>\n",
       "      <td>2/28/2017</td>\n",
       "      <td>Sebat</td>\n",
       "      <td>11</td>\n",
       "      <td>41.9</td>\n",
       "      <td>1.84</td>\n",
       "      <td>pending</td>\n",
       "      <td>pending</td>\n",
       "      <td>pending</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>REACH000891</td>\n",
       "      <td>F0320-04</td>\n",
       "      <td>F0320</td>\n",
       "      <td>2/26/2010</td>\n",
       "      <td>multiple</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0320-02</td>\n",
       "      <td>F0320-03</td>\n",
       "      <td>Sibling</td>\n",
       "      <td>...</td>\n",
       "      <td>2/28/2017</td>\n",
       "      <td>Sebat</td>\n",
       "      <td>11</td>\n",
       "      <td>119.7</td>\n",
       "      <td>1.84</td>\n",
       "      <td>pending</td>\n",
       "      <td>pending</td>\n",
       "      <td>pending</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>REACH000892</td>\n",
       "      <td>F0320-05</td>\n",
       "      <td>F0320</td>\n",
       "      <td>10/14/2011</td>\n",
       "      <td>multiple</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F0320-02</td>\n",
       "      <td>F0320-03</td>\n",
       "      <td>Sibling</td>\n",
       "      <td>...</td>\n",
       "      <td>2/28/2017</td>\n",
       "      <td>Sebat</td>\n",
       "      <td>12</td>\n",
       "      <td>134.1</td>\n",
       "      <td>1.85</td>\n",
       "      <td>pending</td>\n",
       "      <td>pending</td>\n",
       "      <td>pending</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>REACH000893</td>\n",
       "      <td>F0320-06</td>\n",
       "      <td>F0320</td>\n",
       "      <td>7/8/2013</td>\n",
       "      <td>multiple</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cardiac Defects, ASD/VSD</td>\n",
       "      <td>F0320-02</td>\n",
       "      <td>F0320-03</td>\n",
       "      <td>Sibling</td>\n",
       "      <td>...</td>\n",
       "      <td>2/28/2017</td>\n",
       "      <td>Sebat</td>\n",
       "      <td>12</td>\n",
       "      <td>47.7</td>\n",
       "      <td>1.85</td>\n",
       "      <td>pending</td>\n",
       "      <td>pending</td>\n",
       "      <td>pending</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>893 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sample_ID Subject_ID Family_ID         DOB Family_Type Affected  \\\n",
       "0    REACH000001   F0001-01     F0001   3/26/2007        trio      Yes   \n",
       "1    REACH000107   F0001-02     F0001    8/9/1972        trio      Yes   \n",
       "2    REACH000226   F0001-03     F0001   9/27/1969        trio      Yes   \n",
       "3    REACH000002   F0002-01     F0002  11/19/2007  incomplete      Yes   \n",
       "4    REACH000003   F0003-01     F0003    8/9/2000  incomplete      Yes   \n",
       "..           ...        ...       ...         ...         ...      ...   \n",
       "888  REACH000889   F0320-02     F0320   1/15/1981    multiple       No   \n",
       "889  REACH000890   F0320-03     F0320    7/9/1980    multiple       No   \n",
       "890  REACH000891   F0320-04     F0320   2/26/2010    multiple       No   \n",
       "891  REACH000892   F0320-05     F0320  10/14/2011    multiple       No   \n",
       "892  REACH000893   F0320-06     F0320    7/8/2013    multiple      Yes   \n",
       "\n",
       "                    Diagnosis_LAB Mother_ID Father_ID Rel_Proband  ...  \\\n",
       "0                          Autism  F0001-02  F0001-03     Proband  ...   \n",
       "1                          Autism   Unknown   Unknown         Mom  ...   \n",
       "2              Autism, PTSD, ADHD   Unknown   Unknown         Dad  ...   \n",
       "3                          Autism   Unknown   Unknown     Proband  ...   \n",
       "4                          Autism   Unknown   Unknown     Proband  ...   \n",
       "..                            ...       ...       ...         ...  ...   \n",
       "888  Crohn's Disease, Lupus (SLE)  F8888-88  F8888-88         Mom  ...   \n",
       "889                           NaN  F8888-88  F8888-88         Dad  ...   \n",
       "890                           NaN  F0320-02  F0320-03     Sibling  ...   \n",
       "891                           NaN  F0320-02  F0320-03     Sibling  ...   \n",
       "892      Cardiac Defects, ASD/VSD  F0320-02  F0320-03     Sibling  ...   \n",
       "\n",
       "    Date sent for DNA extraction Location of DNA extraction  DNA Box  \\\n",
       "0                        Unknown                     Gleeson       1   \n",
       "1                        Unknown                     Gleeson       2   \n",
       "2                        Unknown                     Gleeson       3   \n",
       "3                        Unknown                     Gleeson       1   \n",
       "4                        Unknown                     Gleeson       1   \n",
       "..                           ...                         ...     ...   \n",
       "888                    2/28/2017                       Sebat      11   \n",
       "889                    2/28/2017                       Sebat      11   \n",
       "890                    2/28/2017                       Sebat      11   \n",
       "891                    2/28/2017                       Sebat      12   \n",
       "892                    2/28/2017                       Sebat      12   \n",
       "\n",
       "    Concentration (ng/uL)     260/280 Date sent for Sequencing  \\\n",
       "0                    60.0        1.80                 9/9/2013   \n",
       "1                    60.0         NaN                 9/9/2013   \n",
       "2                    60.0         NaN                 9/9/2013   \n",
       "3              Incomplete  Incomplete        Incomplete family   \n",
       "4              Incomplete  Incomplete        Incomplete family   \n",
       "..                    ...         ...                      ...   \n",
       "888                  36.2        1.79                  pending   \n",
       "889                  41.9        1.84                  pending   \n",
       "890                 119.7        1.84                  pending   \n",
       "891                 134.1        1.85                  pending   \n",
       "892                  47.7        1.85                  pending   \n",
       "\n",
       "          WGS Provider (Sample Well) Plate Name.Sample.ID Affected_orig  \\\n",
       "0             Illumina                  LP6005688-DNA_E11           Yes   \n",
       "1             Illumina                  LP6005688-DNA_F11           Yes   \n",
       "2             Illumina                  LP6005688-DNA_G11           Yes   \n",
       "3    Incomplete family                  Incomplete family           Yes   \n",
       "4    Incomplete family                  Incomplete family           Yes   \n",
       "..                 ...                                ...           ...   \n",
       "888            pending                            pending            No   \n",
       "889            pending                            pending            No   \n",
       "890            pending                            pending            No   \n",
       "891            pending                            pending            No   \n",
       "892            pending                            pending           Yes   \n",
       "\n",
       "    Affected_ASD  \n",
       "0            Yes  \n",
       "1            Yes  \n",
       "2            Yes  \n",
       "3            Yes  \n",
       "4            Yes  \n",
       "..           ...  \n",
       "888           No  \n",
       "889           No  \n",
       "890           No  \n",
       "891           No  \n",
       "892          Yes  \n",
       "\n",
       "[893 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_file = '/expanse/projects/sebat1/miladm/UCSD/LONG_READ_COHORT/REACH_sample_info.tsv'\n",
    "df_meta = pd.read_table(meta_file, sep='\\t', header=0)\n",
    "\n",
    "rename_samples_dict = {'REACH000236': 'REACH000236_PB', \n",
    "                       'REACH000436': 'REACH000436_PB', \n",
    "                       'REACH000530': 'REACH000530_PB', \n",
    "                       'REACH000531': 'REACH000531_ONT', \n",
    "                       'REACH000532': 'REACH000532_ONT'}\n",
    "df_meta['Sample_ID'] = df_meta.apply(lambda row: rename_samples_dict[row['Sample_ID']] \n",
    "                                     if row['Sample_ID'] in rename_samples_dict else row['Sample_ID'], axis=1)\n",
    "display(df_meta)\n",
    "\n",
    "aff_dict = {}\n",
    "for sample, aff in zip(df_meta['Sample_ID'].tolist(), df_meta['Affected'].tolist()):\n",
    "    aff_dict[sample] = aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c0da10-e531-44ed-af42-72b77b455ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/smmortazavi/job_34631928/ipykernel_1825772/1272275152.py:2: DtypeWarning: Columns (24,25,48,49,50,51,52,53,54,55,59,60,61,62,63,64,65,66,71,72,73,74,75,76,77,81,82,83,84,85,86,87,88,92,93,94,95,96,97,98,99,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,219,225,230,231,237,242,243,248,249,254,255,260,261,266,267,272,273,278,279,284,285) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_table(file_name, sep='\\t', header=0)\n"
     ]
    }
   ],
   "source": [
    "file_name = 'test.tsv'\n",
    "df = pd.read_table(file_name, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e988c58-936e-4e5e-ab17-ad8d9548873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(918557, 362)\n",
      "(794759, 362)\n",
      "25\n",
      "(652348, 362)\n"
     ]
    }
   ],
   "source": [
    "# filter homopolymers\n",
    "df_flt = df.loc[df.PERIOD>1]\n",
    "print(df.shape)\n",
    "print(df_flt.shape)\n",
    "\n",
    "# filter trs based on missingness\n",
    "file_tr_ids = '/expanse/projects/sebat1/miladm/UCSD/LONG_READ_COHORT/TRs_LongTR/FAM/variant_prior/tr_missingness/tr_ids_missingness_25.tsv'\n",
    "#file_tr_ids = '/expanse/projects/sebat1/miladm/UCSD/LONG_READ_COHORT/TRs_LongTR/FAM/variant_prior/tr_missingness/tr_ids_missingness_20.tsv'\n",
    "#file_tr_ids = '/expanse/projects/sebat1/miladm/UCSD/LONG_READ_COHORT/TRs_LongTR/FAM/variant_prior/tr_missingness/tr_ids_missingness_15.tsv'\n",
    "tr_miss_level = file_tr_ids.split('_')[-1].rstrip('.tsv')\n",
    "print(tr_miss_level)\n",
    "df_tr_ids = pd.read_table(file_tr_ids)\n",
    "#df_tr_ids\n",
    "\n",
    "df_flt = df_flt.loc[df_flt.ID.isin(df_tr_ids.tr_id)]\n",
    "print(df_flt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd49142-6115-4690-8467-479307f278c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "(209, 1)\n",
      "209\n"
     ]
    }
   ],
   "source": [
    "#filter_samples = False\n",
    "filter_samples = True\n",
    "#file_sam_missing = '/expanse/projects/sebat1/miladm/UCSD/LONG_READ_COHORT/TRs_LongTR/FAM/variant_prior/tr_missingness/samples_missingness_30.tsv'\n",
    "#file_sam_missing = '/expanse/projects/sebat1/miladm/UCSD/LONG_READ_COHORT/TRs_LongTR/FAM/variant_prior/tr_missingness/samples_missingness_35.tsv'\n",
    "#file_sam_missing = '/expanse/projects/sebat1/miladm/UCSD/LONG_READ_COHORT/TRs_LongTR/FAM/variant_prior/tr_missingness/samples_missingness_40.tsv'\n",
    "file_sam_missing = '/expanse/projects/sebat1/miladm/UCSD/LONG_READ_COHORT/TRs_LongTR/FAM/variant_prior/tr_missingness/samples_missingness_50.tsv'\n",
    "\n",
    "sam_miss_level = file_sam_missing.split('_')[-1].rstrip('.tsv')\n",
    "print(sam_miss_level)\n",
    "\n",
    "df_sam_missing = pd.read_table(file_sam_missing, header = 0, sep = \"\\t\", names = ['SAMPLE'])\n",
    "print(df_sam_missing.shape)\n",
    "\n",
    "samples_pass_list = df_sam_missing.SAMPLE.tolist()\n",
    "print(len(samples_pass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "122dd594-3afe-44c6-bccc-bbaf14ddd28a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295      [REACH000544:-0.52|3.24:-37|123:-37|7x123|8, R...\n",
       "65588              [REACH000409:0.15|-5.72:0|-59:-59|2x0|7]\n",
       "80852     [REACH000426:-0.09|-8.08:-53|-116:-116|2x-53|5...\n",
       "117034          [REACH000578:-0.41|-6.08:-6|-54:-54|2x-6|4]\n",
       "145406    [REACH000555:-3.59|0.66:-180|18:-180|2x18|7, R...\n",
       "266086    [REACH000411:0.65|3.92:-7|270:-7|5x270|2, REAC...\n",
       "266091    [REACH000098:0.85|3.58:-25|66:-25|1x66|2, REAC...\n",
       "277956         [REACH000513:-14.92|-0.88:-87|-7:-87|2x-7|7]\n",
       "331578             [REACH000435:-8.81|0.20:-64|0:-64|2x0|4]\n",
       "368633    [REACH000001:0.13|-5.41:0|-52:-52|2x0|13, REAC...\n",
       "368634          [REACH000524:-5.66|-0.20:-57|-4:-57|2x-4|1]\n",
       "394080    [REACH000404:-3.28|-0.97:-53|-18:-53|2x-18|2, ...\n",
       "394247            [REACH000476:0.07|-7.27:0|-62:-62|2x0|14]\n",
       "491849           [REACH000512:-7.45|0.08:-61|-1:-61|2x-1|7]\n",
       "506863    [REACH000234:-5.71|0.16:-70|0:-70|7x0|1, REACH...\n",
       "506885    [REACH000161:0.27|-7.34:0|-75:-75|2x0|2, REACH...\n",
       "567984          [REACH000409:-3.66|-0.32:-67|-9:-67|2x-9|2]\n",
       "623821            [REACH000226:0.15|-8.20:0|-63:-63|2x0|22]\n",
       "680559          [REACH000681:-0.31|-7.41:-7|-56:-56|2x-7|2]\n",
       "692324    [REACH000001:-5.60|-0.87:-89|-19:-89|3x-19|6, ...\n",
       "716382    [REACH000419:0.30|-3.16:0|-90:-90|7x0|7, REACH...\n",
       "716567        [REACH000404:-3.07|-0.38:-74|-13:-74|2x-13|2]\n",
       "717116       [REACH000107:-0.02|-14.91:-2|-168:-168|2x-2|3]\n",
       "747460    [REACH000107:-5.08|0.08:-144|0:-144|2x0|6, REA...\n",
       "816364           [REACH000516:-3.77|0.37:-119|0:-119|2x0|5]\n",
       "849577          [REACH000604:0.04|-18.84:0|-106:-106|2x0|6]\n",
       "Name: LZS3_SAMPLES_SUPP2_Q, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[(df[f'X_{ft}'] == 1) & ~(df[samples_col].isna())][samples_col].str.split(',', expand=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "477b7cb1-27dd-4fe4-896b-9daf3f014f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_lzs(row, col):\n",
    "    if row[col] == '':\n",
    "        return '', '', '', '', ''\n",
    "    samples = [x.split(':')[0] for x in row[col].split(',') if x.split(':')[0] in samples_pass_list]\n",
    "    case_samples = [aff_dict[x.split(':')[0]] for x in row[col].split(',') if x.split(':')[0] in samples_pass_list]\n",
    "    zss = [x.split(':')[1] for x in row[col].split(',') if x.split(':')[0] in samples_pass_list]\n",
    "    gbs = [x.split(':')[2] for x in row[col].split(',') if x.split(':')[0] in samples_pass_list]\n",
    "    supps = [x.split(':')[3] for x in row[col].split(',') if x.split(':')[0] in samples_pass_list]\n",
    "    return ','.join(samples), ','.join(case_samples), ','.join(zss), ','.join(gbs), ','.join(supps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e570904c-e055-42cb-a93a-5ab6b686d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLIp9_DEV_BR_GENE_10_cds\n",
      "PLIp9_DEV_BR_GENE_10_utr\n",
      "PLIp9_DEV_BR_GENE_10_intron\n",
      "DEV_BR_GENE_10_cds\n",
      "DEV_BR_GENE_10_utr\n",
      "DEV_BR_GENE_10_intron\n",
      "PLIp9_cds\n",
      "PLIp9_utr\n",
      "PLIp9_intron\n",
      "LOWPLI_cds\n",
      "LOWPLI_utr\n",
      "LOWPLI_intron\n",
      "intergenic\n",
      "genic\n",
      "genic_cds\n",
      "genic_utr\n",
      "genic_intron\n"
     ]
    }
   ],
   "source": [
    "### make tables of variants in the burden tests\n",
    "sub_dir = 'burden_tables/'\n",
    "\n",
    "zs_thr = 3\n",
    "supp_thr = 2\n",
    "#fts = ['FDR_ASD_cds', 'PLIp9_DEV_BR_GENE_10_cds', 'DEV_BR_GENE_10_cds', 'PLIp9_cds', 'LOWPLI_cds', 'PLIp9_utr']\n",
    "fts = ['PLIp9_DEV_BR_GENE_10_cds', 'PLIp9_DEV_BR_GENE_10_utr', 'PLIp9_DEV_BR_GENE_10_intron', \n",
    "       'DEV_BR_GENE_10_cds', 'DEV_BR_GENE_10_utr', 'DEV_BR_GENE_10_intron', \n",
    "       'PLIp9_cds', 'PLIp9_utr', 'PLIp9_intron', \n",
    "       'LOWPLI_cds', 'LOWPLI_utr', 'LOWPLI_intron', 'intergenic', 'genic', 'genic_cds', 'genic_utr', 'genic_intron']\n",
    "\n",
    "cols = ['CHROM', 'POS', 'END', 'ID', 'GENCODE', 'PERIOD', 'MEAN_GB', 'STD_GB', 'SN_GB', 'SYMBOL', 'Consequence',\n",
    "        'GENES_PLI', 'MAX_PLI', 'MAX_PLI_GENE', \n",
    "        'GENES_LOEUF', 'MIN_LOEUF', 'MIN_LOEUF_GENE', \n",
    "        'SIG_FDR_ASD_GENES', 'SIG_FDR_DD_GENES', 'SIG_FDR_NDD_GENES', \n",
    "        f'LZS{zs_thr}_SAMPLES_SUPP{supp_thr}_Q', f'case_LZS{zs_thr}_SAMPLES_SUPP{supp_thr}_Q']\n",
    "#REACH000544:-0.52|3.24:-37|123:-37|7x123|8\n",
    "col_exp = f'LZS{zs_thr}_SAMPLES_SUPP{supp_thr}_Q'\n",
    "new_cols = ['Samples_pass', 'case_status', 'Z-scores', 'base_pair_deviation', 'read_supp']\n",
    "\n",
    "samples_col = f'LZS{zs_thr}_SAMPLES_SUPP{supp_thr}_Q'\n",
    "for ft in fts:\n",
    "    print(ft)\n",
    "    this_df = df_flt.loc[(df_flt[f'X_{ft}'] == 1) & ~(df_flt[samples_col].isna())][cols]\n",
    "    this_df[new_cols] = this_df.apply(lambda row: expand_lzs(row, col_exp), axis=1, result_type='expand')\n",
    "    # remove the calls with no acceptable sample\n",
    "    this_df = this_df.loc[this_df['Samples_pass'] != '']\n",
    "    file_name = dir_tbl + sub_dir + f'table_{ft}_LZS{zs_thr}_SUPP{supp_thr}_filterSamples{sam_miss_level}_TRmissing{tr_miss_level}.tsv'\n",
    "    this_df.to_csv(file_name, sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01ec608c-a144-4210-a8b7-f5f62e1fa118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>MEAN_COVERAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG004</td>\n",
       "      <td>ONT</td>\n",
       "      <td>81.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REACH000626</td>\n",
       "      <td>ONT</td>\n",
       "      <td>10.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REACH000546</td>\n",
       "      <td>ONT</td>\n",
       "      <td>10.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REACH000683</td>\n",
       "      <td>ONT</td>\n",
       "      <td>9.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REACH000563</td>\n",
       "      <td>ONT</td>\n",
       "      <td>8.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>REACH000284</td>\n",
       "      <td>PB</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>REACH000672</td>\n",
       "      <td>PB</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>REACH000292</td>\n",
       "      <td>PB</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>REACH000066</td>\n",
       "      <td>PB</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2602-2-1</td>\n",
       "      <td>PB</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SAMPLE COHORT  MEAN_COVERAGE\n",
       "0          HG004    ONT          81.44\n",
       "1    REACH000626    ONT          10.51\n",
       "2    REACH000546    ONT          10.87\n",
       "3    REACH000683    ONT           9.97\n",
       "4    REACH000563    ONT           8.68\n",
       "..           ...    ...            ...\n",
       "283  REACH000284     PB           3.43\n",
       "284  REACH000672     PB           5.02\n",
       "285  REACH000292     PB           9.00\n",
       "286  REACH000066     PB           1.61\n",
       "287     2602-2-1     PB           0.89\n",
       "\n",
       "[288 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_cov = '/expanse/projects/sebat1/s3/data/sebat/long_reads_pipeline_results/coverages_mod.tsv'\n",
    "#file_cov = '/tscc/projects/ps-sebat1/s3/data/sebat/long_reads_pipeline_results/coverages_mod.tsv'\n",
    "df_cov = pd.read_table(file_cov, header=0, sep='\\t')\n",
    "multiplat_samples = ['REACH000236', 'REACH000530', 'REACH000531', 'REACH000532', 'REACH000436']\n",
    "df_cov['SAMPLE'] = df_cov.apply(lambda row: row['SAMPLE']+'_'+row['COHORT'] if row['SAMPLE'] in multiplat_samples else row['SAMPLE'], axis=1)\n",
    "df_cov_high = df_cov.loc[df_cov.SAMPLE.str.startswith('REACH000') & (df_cov.MEAN_COVERAGE > 9)]\n",
    "display(df_cov)\n",
    "high_cov_samples = df_cov_high.SAMPLE.tolist()\n",
    "#print(high_cov_samples)\n",
    "\n",
    "def get_plat(sample):\n",
    "    try:\n",
    "        ret = df_cov[df_cov.SAMPLE == sample]['COHORT'].values[0]\n",
    "    except:\n",
    "        print(f'problem with samples: {sample}')\n",
    "        ret = ''\n",
    "    return ret\n",
    "\n",
    "plat_dict = {sample: get_plat(sample) for sample in df_cov.SAMPLE.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a7c6e2-b02e-46c5-bb60-4a44d747e80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>famid</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dad</th>\n",
       "      <th>mom</th>\n",
       "      <th>sex</th>\n",
       "      <th>phen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2323</td>\n",
       "      <td>2323-2-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2602</td>\n",
       "      <td>2602-2-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3392</td>\n",
       "      <td>3392-2-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3538</td>\n",
       "      <td>3538-2-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3939</td>\n",
       "      <td>3939-3-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>F0270</td>\n",
       "      <td>REACH000681</td>\n",
       "      <td>REACH000683</td>\n",
       "      <td>REACH000682</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>F0270</td>\n",
       "      <td>REACH000682</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>F0270</td>\n",
       "      <td>REACH000683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>F0270</td>\n",
       "      <td>REACH000684</td>\n",
       "      <td>REACH000683</td>\n",
       "      <td>REACH000682</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>F0270</td>\n",
       "      <td>REACH000685</td>\n",
       "      <td>REACH000683</td>\n",
       "      <td>REACH000682</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     famid    sample_id          dad          mom  sex  phen\n",
       "0     2323     2323-2-1            0            0    2     2\n",
       "1     2602     2602-2-1            0            0    2     2\n",
       "2     3392     3392-2-3            0            0    2     2\n",
       "3     3538     3538-2-1            0            0    2     2\n",
       "4     3939     3939-3-1            0            0    2     2\n",
       "..     ...          ...          ...          ...  ...   ...\n",
       "275  F0270  REACH000681  REACH000683  REACH000682    1     2\n",
       "276  F0270  REACH000682            0            0    2     2\n",
       "277  F0270  REACH000683            0            0    1     2\n",
       "278  F0270  REACH000684  REACH000683  REACH000682    1     2\n",
       "279  F0270  REACH000685  REACH000683  REACH000682    1     1\n",
       "\n",
       "[280 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete trios:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>famid</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dad</th>\n",
       "      <th>mom</th>\n",
       "      <th>sex</th>\n",
       "      <th>phen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F0026</td>\n",
       "      <td>REACH000026</td>\n",
       "      <td>REACH000270</td>\n",
       "      <td>REACH000269</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>F0058</td>\n",
       "      <td>REACH000058</td>\n",
       "      <td>REACH000440</td>\n",
       "      <td>REACH000439</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>F0065</td>\n",
       "      <td>REACH000065</td>\n",
       "      <td>REACH000067</td>\n",
       "      <td>REACH000066</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>F0078</td>\n",
       "      <td>REACH000086</td>\n",
       "      <td>REACH000088</td>\n",
       "      <td>REACH000087</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>F0078</td>\n",
       "      <td>REACH000089</td>\n",
       "      <td>REACH000088</td>\n",
       "      <td>REACH000087</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>F0266</td>\n",
       "      <td>REACH000660</td>\n",
       "      <td>REACH000662</td>\n",
       "      <td>REACH000661</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>F0266</td>\n",
       "      <td>REACH000663</td>\n",
       "      <td>REACH000662</td>\n",
       "      <td>REACH000661</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>F0270</td>\n",
       "      <td>REACH000681</td>\n",
       "      <td>REACH000683</td>\n",
       "      <td>REACH000682</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>F0270</td>\n",
       "      <td>REACH000684</td>\n",
       "      <td>REACH000683</td>\n",
       "      <td>REACH000682</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>F0270</td>\n",
       "      <td>REACH000685</td>\n",
       "      <td>REACH000683</td>\n",
       "      <td>REACH000682</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     famid    sample_id          dad          mom  sex  phen\n",
       "10   F0026  REACH000026  REACH000270  REACH000269    1     2\n",
       "11   F0058  REACH000058  REACH000440  REACH000439    1     2\n",
       "12   F0065  REACH000065  REACH000067  REACH000066    1     2\n",
       "15   F0078  REACH000086  REACH000088  REACH000087    1     2\n",
       "18   F0078  REACH000089  REACH000088  REACH000087    2     2\n",
       "..     ...          ...          ...          ...  ...   ...\n",
       "271  F0266  REACH000660  REACH000662  REACH000661    2     2\n",
       "274  F0266  REACH000663  REACH000662  REACH000661    1     1\n",
       "275  F0270  REACH000681  REACH000683  REACH000682    1     2\n",
       "278  F0270  REACH000684  REACH000683  REACH000682    1     2\n",
       "279  F0270  REACH000685  REACH000683  REACH000682    1     1\n",
       "\n",
       "[117 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "1    74\n",
      "2    43\n",
      "Name: count, dtype: int64\n",
      "phen\n",
      "2    92\n",
      "1    25\n",
      "Name: count, dtype: int64\n",
      "len(parent_kids_dict): 126\n",
      "len(mom_kids_dict): 63\n",
      "len(dad_kids_dict): 63\n",
      "len(mate_dict): 126\n"
     ]
    }
   ],
   "source": [
    "file_psam = '/expanse/projects/sebat1/miladm/UCSD/LONG_READ_COHORT/process_IL_LR/HWE/REACH_LR_platform.psam'\n",
    "df_p = pd.read_table(file_psam, sep='\\t', header=None, names = ['famid', 'sample_id', 'dad', 'mom', 'sex', 'phen'])\n",
    "display(df_p)\n",
    "\n",
    "famid_samples_dict = {}\n",
    "for famid in df_p.famid.unique():\n",
    "    famid_samples_dict[famid] = df_p.loc[df_p.famid==famid]['sample_id'].tolist()\n",
    "\n",
    "sample_famid_dict = {}\n",
    "for sam, famid in zip(df_p.sample_id, df_p.famid):\n",
    "    sample_famid_dict[sam] = famid\n",
    "\n",
    "print('complete trios:')\n",
    "df_trios = df_p.loc[df_p.dad.isin(df_p.sample_id) & df_p.mom.isin(df_p.sample_id)]\n",
    "display(df_trios)\n",
    "print(df_trios.sex.value_counts())\n",
    "print(df_trios.phen.value_counts())\n",
    "\n",
    "# make mom and dad dictionary\n",
    "sample_dad_dict = {}\n",
    "sample_mom_dict = {}\n",
    "for sample, dad, mom in zip(df_trios.sample_id, df_trios.dad, df_trios.mom):\n",
    "    #print(sample, dad, mom)\n",
    "    sample_dad_dict[sample] = dad\n",
    "    sample_mom_dict[sample] = mom\n",
    "\n",
    "parents_set_lr = set(df_trios.dad.tolist()) | set(df_trios.mom.tolist())\n",
    "#print(f'len(parents_set_lr): {len(parents_set_lr)}')\n",
    "#print(parents_set_lr)\n",
    "\n",
    "parents_set_pb = set([x for x in parents_set_lr if plat_dict[x]=='PB'])\n",
    "parents_set_ont = set([x for x in parents_set_lr if plat_dict[x]=='ONT'])\n",
    "#print('len(parents_set_pb):', len(parents_set_pb))\n",
    "#print('len(parents_set_ont):', len(parents_set_ont))\n",
    "\n",
    "parent_kids_dict = {}\n",
    "mom_kids_dict = {}\n",
    "dad_kids_dict = {}\n",
    "for parent in parents_set_lr:\n",
    "    parent_kids_dict[parent] = df_trios.loc[(df_trios.dad == parent) | (df_trios.mom == parent)].sample_id.tolist()\n",
    "    if parent in df_trios.dad.tolist():\n",
    "        dad_kids_dict[parent] = df_trios.loc[(df_trios.dad == parent)].sample_id.tolist()\n",
    "    if parent in df_trios.mom.tolist():\n",
    "        mom_kids_dict[parent] = df_trios.loc[(df_trios.mom == parent)].sample_id.tolist()\n",
    "print(f'len(parent_kids_dict): {len(parent_kids_dict)}')\n",
    "#print(parent_kids_dict)\n",
    "print(f'len(mom_kids_dict): {len(mom_kids_dict)}')\n",
    "#print(mom_kids_dict)\n",
    "print(f'len(dad_kids_dict): {len(dad_kids_dict)}')\n",
    "#print(dad_kids_dict)\n",
    "\n",
    "mate_dict = {}\n",
    "for dad, mom in zip(df_trios.dad, df_trios.mom):\n",
    "    mate_dict[dad] = mom\n",
    "    mate_dict[mom] = dad\n",
    "print(f'len(mate_dict): {len(mate_dict)}')\n",
    "#print(mate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b5c23b3-6550-4f45-a93d-9d22a67c0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_close(kid_gt, par_gts, err_thr=0.2):\n",
    "    err_min = np.min([abs((kid_gt-par_gt) / (par_gt+.001)) for par_gt in par_gts])\n",
    "    if err_min <= err_thr:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def get_denovo(row, col, sample_mom_dict, sample_dad_dict, gt_thr=0, len_thr=0, supp_thr=1):\n",
    "    q_samples = [x.split(':')[0] for x in row['Q90_SAMPLES_GB'].split(',') if x != '.']\n",
    "    hp1_samples = [x.split(':')[0] for x in row['HP1_SAMPLES_PDP'].split(',') if x != '.']\n",
    "    hp2_samples = [x.split(':')[0] for x in row['HP2_SAMPLES_PDP'].split(',') if x != '.']\n",
    "    #hem_samples = [x.split(':')[0] for x in row['HEM_SAMPLES_DP'].split(',') if x != '.']\n",
    "\n",
    "    kids = [x.split(':')[0] for x in row[col].split(',') if x.split(':')[0] in sample_mom_dict]\n",
    "    \n",
    "    moms = [x.split(':')[0] for x in row[col].split(',') if x.split(':')[0] in mom_kids_dict]\n",
    "    dads = [x.split(':')[0] for x in row[col].split(',') if x.split(':')[0] in dad_kids_dict]\n",
    "    mom_mates = [mate_dict[x] for x in moms]\n",
    "    dad_mates = [mate_dict[x] for x in dads]\n",
    "    mom_kids = [mom_kids_dict[x] for x in moms]\n",
    "    dad_kids = [dad_kids_dict[x] for x in dads]\n",
    "\n",
    "\n",
    "    sample_gt_dict = {x.split(':')[0]: (float(x.split(':')[1].split('|')[0]), float(x.split(':')[1].split('|')[1])) \n",
    "                      if ((x != '.') and (len(x.split(':')[1].split('|'))==2)) \n",
    "                      else ((float(x.split(':')[1].split('|')[0]),) if ((x != '.') and (len(x.split(':')[1].split('|'))==1)) else '.')\n",
    "                      for x in row[col].split(',')}\n",
    "    sample_len_dict = {x.split(':')[0]: (int(x.split(':')[2].split('|')[0]), int(x.split(':')[2].split('|')[1])) \n",
    "                      if ((x != '.') and (len(x.split(':')[2].split('|'))==2)) \n",
    "                      else ((int(x.split(':')[2].split('|')[0]),) if ((x != '.') and (len(x.split(':')[2].split('|'))==1)) else '.')\n",
    "                      for x in row[col].split(',')}\n",
    "\n",
    "    sample_supp_dict = {x.split(':')[0]: {int(x.split(':')[-1].split('x')[0].split('|')[0]): int(x.split(':')[-1].split('x')[0].split('|')[1]), \n",
    "                                           int(x.split(':')[-1].split('x')[1].split('|')[0]): int(x.split(':')[-1].split('x')[1].split('|')[1])} \n",
    "                        if ((x != '.') and (len(x.split(':')[-1].split('x'))==2)) \n",
    "                        else ({int(x.split(':')[-1].split('x')[0].split('|')[0]): int(x.split(':')[-1].split('x')[0].split('|')[1])} \n",
    "                              if ((x != '.') and (len(x.split(':')[-1].split('x'))==1)) else '.') for x in row[col].split(',')}\n",
    "    sample_info_dict = {x.split(':')[0]: x for x in row[col].split(',')}\n",
    "\n",
    "    dn_kids = []\n",
    "    dn_kids_case = []\n",
    "    dn_dads = []\n",
    "    dn_moms = []\n",
    "    dn_plat = []\n",
    "    for kid in kids:\n",
    "        kid_gts = sample_gt_dict[kid]\n",
    "        kid_lens = sample_len_dict[kid]\n",
    "        kid_supp = sample_supp_dict[kid]\n",
    "        gt_good = False\n",
    "        for gt, l in zip(kid_gts, kid_lens):\n",
    "            supp = kid_supp[l]\n",
    "            if (abs(gt) >= gt_thr) and (supp >= supp_thr) and (abs(l) >= len_thr):\n",
    "                gt_good = True\n",
    "        if (not gt_good):\n",
    "            continue\n",
    "\n",
    "        dad = sample_dad_dict[kid]\n",
    "        mom = sample_mom_dict[kid]\n",
    "\n",
    "        # make sure mom and dad have at least one read in each phase\n",
    "        if (mom not in hp1_samples) or (mom not in hp2_samples) or (dad not in hp1_samples) or (dad not in hp2_samples):\n",
    "            continue\n",
    "\n",
    "        dad_gts = None\n",
    "        if dad in sample_gt_dict:\n",
    "            dad_gts = sample_gt_dict[dad]\n",
    "        mom_gts = None\n",
    "        if mom in sample_gt_dict:\n",
    "            mom_gts = sample_gt_dict[mom]\n",
    "\n",
    "        is_denovo = False\n",
    "        for gt, l in zip(kid_gts, kid_lens):\n",
    "            supp = kid_supp[l]\n",
    "            if (abs(gt) >= gt_thr) and (supp >= supp_thr) and (abs(l) >= len_thr):\n",
    "                if (dad_gts==None or (not is_close(gt, dad_gts))) and (mom_gts==None or (not is_close(gt, mom_gts))):\n",
    "                    is_denovo = True\n",
    "        if is_denovo:\n",
    "            dn_kids.append(sample_info_dict[kid])\n",
    "            dn_kids_case.append(aff_dict[kid])\n",
    "            dn_dads.append(sample_info_dict[dad] if dad in sample_info_dict else dad)\n",
    "            dn_moms.append(sample_info_dict[mom] if mom in sample_info_dict else mom)\n",
    "            dn_plat.append(plat_dict[kid])\n",
    "\n",
    "    return ','.join(dn_kids), ','.join(dn_kids_case), ','.join(dn_dads), ','.join(dn_moms), ','.join(dn_plat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3401cc6-32ad-42ab-82e7-e987ec2177e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_tables/denovos/table_denovo_LZS3_SUPP3_len50_TRmissing25.tsv\n"
     ]
    }
   ],
   "source": [
    "### make talbe of putatively De novo TRs\n",
    "sub_dir = 'denovos/'\n",
    "\n",
    "zs_thr = 3\n",
    "len_thr = 50\n",
    "supp_thr = 3\n",
    "col = 'ZS_SAMPLES'\n",
    "df_flt_dn = pd.DataFrame(df_flt)\n",
    "cols_dn = [f'denovo_ZS{zs_thr}_len{len_thr}_supp{supp_thr}',\n",
    "           f'case_denovo',\n",
    "           f'denovoDADs_ZS{zs_thr}_len{len_thr}_supp{supp_thr}', \n",
    "           f'denovoMOMs_ZS{zs_thr}_len{len_thr}_supp{supp_thr}', \n",
    "           f'denovoPLAT_ZS{zs_thr}_len{len_thr}_supp{supp_thr}']\n",
    "df_flt_dn[cols_dn] = df_flt.apply(\n",
    "    lambda row: get_denovo(row, col, sample_mom_dict, sample_dad_dict,\n",
    "                           gt_thr=zs_thr, len_thr=len_thr, supp_thr=supp_thr), \n",
    "    axis=1, result_type='expand')\n",
    "\n",
    "# mark varinats which has a PB sample\n",
    "df_flt_dn['denovoPLAT_PB']  = df_flt_dn.apply(lambda row: 1 if 'PB' in row[f'denovoPLAT_ZS{zs_thr}_len{len_thr}_supp{supp_thr}'] else 0, axis=1)\n",
    "\n",
    "# write putatively denovo TRs\n",
    "this_df = df_flt_dn.loc[ (df_flt_dn[f'denovo_ZS{zs_thr}_len{len_thr}_supp{supp_thr}'] != '') ].copy()\n",
    "\n",
    "# extend the sample column\n",
    "col_exp = f'LZS{zs_thr}_SAMPLES_SUPP{supp_thr}_Q'\n",
    "new_cols = ['Samples', 'case_status', 'Z-scores', 'base_pair_deviation', 'read_supp']\n",
    "this_df[col_exp] = this_df[col_exp].fillna('')\n",
    "this_df[new_cols] = this_df.apply(lambda row: expand_lzs(row, col_exp), axis=1, result_type='expand')\n",
    "\n",
    "cols = ['CHROM', 'POS', 'END', 'ID', 'GENCODE', 'PERIOD', 'MEAN_GB', 'STD_GB', 'SN_GB', 'SYMBOL', 'Consequence',\n",
    "        'GENES_PLI', 'MAX_PLI', 'MAX_PLI_GENE', \n",
    "        'GENES_LOEUF', 'MIN_LOEUF', 'MIN_LOEUF_GENE', \n",
    "        'SIG_FDR_ASD_GENES', 'SIG_FDR_DD_GENES', 'SIG_FDR_NDD_GENES',\n",
    "        f'LZS{zs_thr}_SAMPLES_SUPP{supp_thr}_Q', f'case_LZS{zs_thr}_SAMPLES_SUPP{supp_thr}_Q'] + new_cols + cols_dn + ['denovoPLAT_PB']\n",
    "\n",
    "file_name = dir_tbl + sub_dir + f'table_denovo_LZS{zs_thr}_SUPP{supp_thr}_len{len_thr}_TRmissing{tr_miss_level}.tsv'\n",
    "print(file_name)\n",
    "this_df[cols].to_csv(file_name, sep='\\t', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
